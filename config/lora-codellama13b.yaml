base_model: C:\Users\sesal\Documents\AntonioTrovato\CodeLlama-13b-Instruct-hf
hf_model_repo: anto0699/Prompt2OpenSCENARIO-CodeLlama13B-LoRA
hf_dataset_repo: anto0699/Prompt2OpenSCENARIO-LoRA-FineTune
output_dir: runs/codellama13b-lora
seed: 42

# QLoRA / PEFT
lora_r: 32
lora_alpha: 32
lora_dropout: 0.05
target_modules: [q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj]
bias: "none"

# Quantizzazione
load_in_4bit: false
torch_dtype: float64
save_safetensors: true
#bnb_4bit_quant_type: "nf4"
#bnb_4bit_use_double_quant: true
#bnb_4bit_compute_dtype: "bfloat16"

# Training
max_length: 3072
train_batch_size: 1
grad_accum_steps: 16
eval_batch_size: 1
learning_rate: 2.0e-4
weight_decay: 0.0
num_epochs: 2
warmup_ratio: 0.05
lr_scheduler_type: cosine
logging_steps: 10
eval_steps: 200
save_steps: 1000
gradient_checkpointing: true
packing: false

# Hub
push_to_hub: true
hub_model_id: anto0699/Prompt2OpenSCENARIO-CodeLlama13B-LoRA

# Generation (per validazione)
gen_max_new_tokens: 4000
gen_temperature: 0.3
gen_top_p: 0.9
stop_sequence: "</OpenSCENARIO>"

# Valutazione (slot & XSD)
xsd_path: ""   # inserisci il percorso a OpenSCENARIO.xsd se ce l'hai, altrimenti lascialo vuoto
val_split_ratio: 0.1
